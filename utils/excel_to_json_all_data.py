#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Excelè½¬JSONå·¥å…·
å°†Excelæ–‡ä»¶ä¸­çš„æ¯ä¸ªå·¥ä½œè¡¨è½¬æ¢ä¸ºå•ç‹¬çš„JSONæ–‡ä»¶

ä¾èµ–åº“ï¼š
pip install pandas openpyxl xlrd
"""

import pandas as pd
import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Optional
import argparse
from datetime import datetime


class ExcelToJsonConverter:
    """Excelè½¬JSONè½¬æ¢å™¨"""

    def __init__(self, excel_file: str, output_dir: str = None):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨

        Args:
            excel_file: Excelæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºExcelæ–‡ä»¶åŒçº§ç›®å½•ä¸‹çš„jsonæ–‡ä»¶å¤¹
        """
        self.excel_file = Path(excel_file)
        if not self.excel_file.exists():
            raise FileNotFoundError(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_file}")

        # è®¾ç½®è¾“å‡ºç›®å½•
        if output_dir:
            self.output_dir = Path(output_dir)
        else:
            self.output_dir = self.excel_file.parent / "json_output"

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(exist_ok=True)

        # è®°å½•è½¬æ¢ç»Ÿè®¡
        self.stats = {
            "total_sheets": 0,
            "successful_conversions": 0,
            "failed_conversions": 0,
            "errors": [],
        }

    def get_sheet_names(self) -> List[str]:
        """è·å–Excelæ–‡ä»¶ä¸­çš„æ‰€æœ‰å·¥ä½œè¡¨åç§°"""
        try:
            with pd.ExcelFile(self.excel_file) as xls:
                return xls.sheet_names
        except Exception as e:
            print(f"âŒ è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
            return []

    def convert_sheet_to_json(
        self,
        sheet_name: str,
        orient: str = "records",
        handle_nan: str = "null",
        date_format: str = "iso",
        hierarchical: bool = False,
        header_row: int = None,
    ) -> Optional[Dict]:
        """
        å°†å•ä¸ªå·¥ä½œè¡¨è½¬æ¢ä¸ºJSONæ•°æ®

        Args:
            sheet_name: å·¥ä½œè¡¨åç§°
            orient: JSONæ ¼å¼ ('records', 'index', 'values', 'table', 'hierarchical')
            handle_nan: NaNå€¼å¤„ç†æ–¹å¼ ('null', 'drop', 'fill')
            date_format: æ—¥æœŸæ ¼å¼ ('iso', 'epoch')
            hierarchical: æ˜¯å¦å¤„ç†å±‚çº§ç»“æ„
            header_row: æŒ‡å®šåˆ—æ ‡é¢˜æ‰€åœ¨è¡Œå·ï¼ˆ0å¼€å§‹ï¼‰ï¼ŒNoneè¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹

        Returns:
            è½¬æ¢åçš„JSONæ•°æ®
        """
        try:
            # å…ˆè¯»å–åŸå§‹æ•°æ®ï¼ˆä¸æŒ‡å®šheaderï¼‰
            df_raw = pd.read_excel(self.excel_file, sheet_name=sheet_name, header=None)

            print(f"ğŸ“Š å¤„ç†å·¥ä½œè¡¨: {sheet_name} (åŸå§‹å½¢çŠ¶: {df_raw.shape})")
            print("ğŸ” åŸå§‹å‰å‡ è¡Œæ•°æ®é¢„è§ˆ:")
            for i in range(min(5, len(df_raw))):
                row_data = [str(x) if not pd.isna(x) else "NaN" for x in df_raw.iloc[i]]
                print(f"  ç¬¬{i+1}è¡Œ: {row_data}")

            # å¦‚æœæ˜¯å±‚çº§ç»“æ„æ ¼å¼ï¼Œä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œå¤„ç†
            if orient == "hierarchical" or hierarchical:
                return self._convert_to_hierarchical_json(df_raw, sheet_name)

            # å¯¹äºå…¶ä»–æ ¼å¼ï¼Œä½¿ç”¨æ ‡å‡†å¤„ç†
            if header_row is not None:
                df = pd.read_excel(
                    self.excel_file, sheet_name=sheet_name, header=header_row
                )
            else:
                df = pd.read_excel(self.excel_file, sheet_name=sheet_name)

            # å¤„ç†NaNå€¼
            if handle_nan == "null":
                df = df.where(pd.notnull(df), None)
            elif handle_nan == "drop":
                df = df.dropna()
            elif handle_nan == "fill":
                df = df.fillna("")

            # å¤„ç†æ—¥æœŸåˆ—
            for col in df.columns:
                if df[col].dtype == "datetime64[ns]":
                    if date_format == "iso":
                        df[col] = df[col].dt.strftime("%Y-%m-%d %H:%M:%S")
                    elif date_format == "epoch":
                        df[col] = df[col].astype(int) // 10**9

            # è½¬æ¢ä¸ºJSONæ ¼å¼
            if orient == "records":
                json_data = df.to_dict(orient="records")
            elif orient == "index":
                json_data = df.to_dict(orient="index")
            elif orient == "values":
                json_data = {"columns": df.columns.tolist(), "data": df.values.tolist()}
            elif orient == "table":
                json_data = df.to_dict(orient="table")
            else:
                json_data = df.to_dict(orient="records")

            return json_data

        except Exception as e:
            error_msg = f"è½¬æ¢å·¥ä½œè¡¨ '{sheet_name}' å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.stats["errors"].append(error_msg)
            return None

    def _convert_to_hierarchical_json(
        self, df_raw: pd.DataFrame, sheet_name: str = None
    ) -> Dict:
        """
        å°†DataFrameè½¬æ¢ä¸ºå±‚çº§JSONç»“æ„
        ä¸“é—¨å¤„ç†å¸¦æœ‰åˆå¹¶å•å…ƒæ ¼çš„åˆ†å±‚è¡¨æ ¼
        """
        print(f"ğŸ“Š åŸå§‹DataFrameå½¢çŠ¶: {df_raw.shape}")

        # æ™ºèƒ½è¯†åˆ«æ ‡é¢˜
        title = sheet_name or "æ•°æ®è¡¨"  # ä¼˜å…ˆä½¿ç”¨å·¥ä½œè¡¨åç§°ä½œä¸ºæ ‡é¢˜

        # å°è¯•åœ¨å‰å‡ è¡Œä¸­å¯»æ‰¾æ›´å¥½çš„æ ‡é¢˜
        for row_idx in range(min(3, len(df_raw))):
            row = df_raw.iloc[row_idx]
            for val in row:
                if not pd.isna(val) and str(val).strip():
                    potential_title = str(val).strip()
                    # å¦‚æœæ‰¾åˆ°åŒ…å«å…³é”®è¯çš„æ›´é•¿æ ‡é¢˜ï¼Œä½¿ç”¨å®ƒ
                    if any(
                        keyword in potential_title
                        for keyword in [
                            "æ¡¥æ¢",
                            "éƒ¨ä»¶",
                            "å…¬è·¯",
                            "å„ç±»",
                            "åˆ†ç±»",
                            "æ„ä»¶",
                            "ç—…å®³",
                        ]
                    ) and len(potential_title) > len(
                        title if title != sheet_name else ""
                    ):
                        title = potential_title
                        print(f"âœ… åœ¨ç¬¬{row_idx+1}è¡Œå‘ç°æ›´å¥½çš„æ ‡é¢˜: {title}")
                        break

        # æ™ºèƒ½è¯†åˆ«åˆ—æ ‡é¢˜è¡Œ
        headers = []
        data_start_row = 0
        total_columns = len(df_raw.columns)

        for row_idx in range(min(4, len(df_raw))):
            row = df_raw.iloc[row_idx]
            non_empty_vals = [
                str(val).strip() for val in row if not pd.isna(val) and str(val).strip()
            ]

            # æ£€æŸ¥è¿™ä¸€è¡Œæ˜¯å¦åƒåˆ—æ ‡é¢˜
            if len(non_empty_vals) >= 3:  # è‡³å°‘3ä¸ªéç©ºå€¼
                header_keywords = [
                    "ç±»å‹",
                    "éƒ¨ä½",
                    "ç±»åˆ«",
                    "è¯„ä»·",
                    "åç§°",
                    "æ¡¥æ¢",
                    "ç»“æ„",
                    "éƒ¨ä»¶",
                    "æ„ä»¶",
                    "ç—…å®³",
                ]
                if any(
                    any(keyword in header for keyword in header_keywords)
                    for header in non_empty_vals
                ):
                    # æ„å»ºå®Œæ•´çš„headersæ•°ç»„
                    headers = []
                    for i in range(total_columns):
                        if i < len(row):
                            val = row.iloc[i]
                            if not pd.isna(val) and str(val).strip():
                                headers.append(str(val).strip())
                            else:
                                headers.append(f"åˆ—{i+1}")
                        else:
                            headers.append(f"åˆ—{i+1}")

                    data_start_row = row_idx + 1
                    print(f"âœ… åœ¨ç¬¬{row_idx+1}è¡Œå‘ç°åˆ—æ ‡é¢˜: {headers}")
                    break

        # å¦‚æœæ²¡æ‰¾åˆ°åˆ—æ ‡é¢˜ï¼Œä½¿ç”¨ç¬¬ä¸€è¡Œä½œä¸ºåˆ—æ ‡é¢˜
        if not headers:
            headers = [f"åˆ—{i+1}" for i in range(total_columns)]
            data_start_row = 1
            print(f"ğŸ”„ ä½¿ç”¨é»˜è®¤åˆ—æ ‡é¢˜: {headers}")

        print(f"ğŸ“‹ æœ€ç»ˆæ ‡é¢˜: {title}")
        print(f"ğŸ“‹ æœ€ç»ˆåˆ—æ ‡é¢˜: {headers}")
        print(f"ğŸ“‹ æ€»åˆ—æ•°: {total_columns}")
        print(f"ğŸ“‹ æ•°æ®å¼€å§‹è¡Œ: ç¬¬{data_start_row+1}è¡Œ")

        # æ„å»ºå±‚çº§æ•°æ®ç»“æ„
        hierarchical_data = {}
        current_type = None
        current_location = None

        # ä»ç¡®å®šçš„æ•°æ®å¼€å§‹è¡Œå¤„ç†æ•°æ®
        for idx in range(data_start_row, len(df_raw)):
            row = df_raw.iloc[idx]

            # è·å–æ‰€æœ‰åˆ—çš„å€¼
            values = []
            for i in range(total_columns):
                if i < len(row):
                    val = row.iloc[i]
                    if pd.isna(val):
                        values.append(None)
                    else:
                        values.append(str(val).strip() if str(val).strip() else None)
                else:
                    values.append(None)

            # è·³è¿‡å®Œå…¨ç©ºç™½çš„è¡Œ
            if all(val is None or val == "" for val in values):
                continue

            print(f"ğŸ” ç¬¬{idx+1}è¡Œæ•°æ®: {values}")

            # å‰ä¸¤åˆ—é€šå¸¸æ˜¯æ¡¥æ¢ç±»å‹å’Œéƒ¨ä½
            bridge_type_val = values[0] if len(values) > 0 else None
            location_val = values[1] if len(values) > 1 else None

            # æ›´æ–°å½“å‰ç±»å‹
            if bridge_type_val and bridge_type_val not in ["NaN", ""]:
                current_type = bridge_type_val
                if current_type not in hierarchical_data:
                    hierarchical_data[current_type] = {}
                    print(f"ğŸ—ï¸  æ–°å»ºæ¡¥æ¢ç±»å‹: {current_type}")

            # æ›´æ–°å½“å‰éƒ¨ä½
            if location_val and location_val not in ["NaN", ""]:
                current_location = location_val
                if (
                    current_type
                    and current_location not in hierarchical_data[current_type]
                ):
                    hierarchical_data[current_type][current_location] = []
                    print(f"   æ–°å»ºéƒ¨ä½: {current_location}")

            # æ·»åŠ å…·ä½“æ•°æ® - ä»ç¬¬3åˆ—å¼€å§‹çš„æ‰€æœ‰æ•°æ®
            if current_type and current_location:
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„æ•°æ®åˆ—ï¼ˆä»ç¬¬3åˆ—å¼€å§‹ï¼‰
                data_columns = values[2:] if len(values) > 2 else []
                if any(val is not None and val != "" for val in data_columns):
                    item = {}

                    # åŠ¨æ€æ·»åŠ æ‰€æœ‰æ•°æ®åˆ—
                    for i, val in enumerate(data_columns):
                        header_index = i + 2  # å¯¹åº”headersçš„ç´¢å¼•
                        if header_index < len(headers):
                            header_name = headers[header_index]

                            # å¤„ç†ç‰¹æ®Šå€¼
                            if val is None or val == "":
                                processed_val = None
                            elif val == "/":
                                processed_val = "/"
                            else:
                                # å°è¯•è½¬æ¢æ•°å­—
                                try:
                                    if "." in val:
                                        processed_val = float(val)
                                    else:
                                        processed_val = int(val)
                                except (ValueError, TypeError):
                                    processed_val = val

                            item[header_name] = processed_val

                    # åªæœ‰å½“itemä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
                    if item:
                        hierarchical_data[current_type][current_location].append(item)
                        print(f"     æ·»åŠ éƒ¨ä»¶: {item}")

        # æ„å»ºæœ€ç»ˆJSONç»“æ„
        result = {
            "title": title,
            "headers": headers,
            "data": hierarchical_data,
            "metadata": {
                "total_types": len(hierarchical_data),
                "total_columns": total_columns,
                "conversion_time": datetime.now().isoformat(),
                "source_sheet": sheet_name or "hierarchical_structure",
                "data_start_row": data_start_row + 1,
            },
        }

        return result

    def save_json_file(
        self, data: Dict, filename: str, indent: int = 2, ensure_ascii: bool = False
    ) -> bool:
        """
        ä¿å­˜JSONæ•°æ®åˆ°æ–‡ä»¶

        Args:
            data: JSONæ•°æ®
            filename: æ–‡ä»¶å
            indent: ç¼©è¿›ç©ºæ ¼æ•°
            ensure_ascii: æ˜¯å¦ç¡®ä¿ASCIIç¼–ç 

        Returns:
            æ˜¯å¦ä¿å­˜æˆåŠŸ
        """
        try:
            output_file = self.output_dir / f"{filename}.json"

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(
                    data, f, indent=indent, ensure_ascii=ensure_ascii, default=str
                )  # default=str å¤„ç†æ— æ³•åºåˆ—åŒ–çš„å¯¹è±¡

            file_size = output_file.stat().st_size
            print(f"âœ… ä¿å­˜æˆåŠŸ: {output_file} ({file_size:,} bytes)")
            return True

        except Exception as e:
            error_msg = f"ä¿å­˜æ–‡ä»¶ '{filename}.json' å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            self.stats["errors"].append(error_msg)
            return False

    def convert_all_sheets(
        self,
        orient: str = "records",
        handle_nan: str = "null",
        date_format: str = "iso",
        filename_prefix: str = "",
        filename_suffix: str = "",
        hierarchical: bool = False,
    ) -> Dict:
        """
        è½¬æ¢æ‰€æœ‰å·¥ä½œè¡¨

        Args:
            orient: JSONæ ¼å¼
            handle_nan: NaNå€¼å¤„ç†æ–¹å¼
            date_format: æ—¥æœŸæ ¼å¼
            filename_prefix: æ–‡ä»¶åå‰ç¼€
            filename_suffix: æ–‡ä»¶ååç¼€
            hierarchical: æ˜¯å¦ä½¿ç”¨å±‚çº§ç»“æ„æ ¼å¼

        Returns:
            è½¬æ¢ç»Ÿè®¡ä¿¡æ¯
        """
        print(f"ğŸš€ å¼€å§‹è½¬æ¢ Excel æ–‡ä»¶: {self.excel_file}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("-" * 50)

        # è·å–æ‰€æœ‰å·¥ä½œè¡¨
        sheet_names = self.get_sheet_names()
        if not sheet_names:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å·¥ä½œè¡¨")
            return self.stats

        self.stats["total_sheets"] = len(sheet_names)
        print(f"ğŸ“‹ å‘ç° {len(sheet_names)} ä¸ªå·¥ä½œè¡¨: {', '.join(sheet_names)}")
        print("-" * 50)

        # é€ä¸ªè½¬æ¢å·¥ä½œè¡¨
        for i, sheet_name in enumerate(sheet_names, 1):
            print(f"\n[{i}/{len(sheet_names)}] å¤„ç†å·¥ä½œè¡¨: {sheet_name}")

            # è½¬æ¢ä¸ºJSON
            json_data = self.convert_sheet_to_json(
                sheet_name, orient, handle_nan, date_format, hierarchical
            )

            if json_data is not None:
                # ç”Ÿæˆæ–‡ä»¶åï¼ˆæ¸…ç†ç‰¹æ®Šå­—ç¬¦ï¼‰
                clean_name = "".join(
                    c for c in sheet_name if c.isalnum() or c in (" ", "-", "_")
                ).strip()
                filename = f"{filename_prefix}{clean_name}{filename_suffix}"

                # ä¿å­˜æ–‡ä»¶
                if self.save_json_file(json_data, filename):
                    self.stats["successful_conversions"] += 1
                else:
                    self.stats["failed_conversions"] += 1
            else:
                self.stats["failed_conversions"] += 1

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        self.print_summary()
        return self.stats

    def print_summary(self):
        """æ‰“å°è½¬æ¢æ‘˜è¦"""
        print("\n" + "=" * 50)
        print("ğŸ“Š è½¬æ¢å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»å·¥ä½œè¡¨æ•°: {self.stats['total_sheets']}")
        print(f"   âœ… æˆåŠŸè½¬æ¢: {self.stats['successful_conversions']}")
        print(f"   âŒ è½¬æ¢å¤±è´¥: {self.stats['failed_conversions']}")

        if self.stats["errors"]:
            print(f"\nâŒ é”™è¯¯è¯¦æƒ…:")
            for error in self.stats["errors"]:
                print(f"   - {error}")

        print(f"\nğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 50)


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å°†Excelæ–‡ä»¶çš„æ¯ä¸ªå·¥ä½œè¡¨è½¬æ¢ä¸ºå•ç‹¬çš„JSONæ–‡ä»¶"
    )

    parser.add_argument("excel_file", help="Excelæ–‡ä»¶è·¯å¾„")
    parser.add_argument("-o", "--output", help="è¾“å‡ºç›®å½•")
    parser.add_argument(
        "--orient",
        choices=["records", "index", "values", "table", "hierarchical"],
        default="records",
        help="JSONæ ¼å¼ (é»˜è®¤: records)",
    )
    parser.add_argument(
        "--hierarchical",
        action="store_true",
        help="ä½¿ç”¨å±‚çº§ç»“æ„æ ¼å¼ï¼ˆé€‚åˆåˆå¹¶å•å…ƒæ ¼è¡¨æ ¼ï¼‰",
    )
    parser.add_argument(
        "--nan",
        choices=["null", "drop", "fill"],
        default="null",
        help="NaNå€¼å¤„ç† (é»˜è®¤: null)",
    )
    parser.add_argument(
        "--date-format",
        choices=["iso", "epoch"],
        default="iso",
        help="æ—¥æœŸæ ¼å¼ (é»˜è®¤: iso)",
    )
    parser.add_argument("--prefix", default="", help="æ–‡ä»¶åå‰ç¼€")
    parser.add_argument("--suffix", default="", help="æ–‡ä»¶ååç¼€")

    args = parser.parse_args()

    try:
        # åˆ›å»ºè½¬æ¢å™¨
        converter = ExcelToJsonConverter(args.excel_file, args.output)

        # æ‰§è¡Œè½¬æ¢
        stats = converter.convert_all_sheets(
            orient=args.orient,
            handle_nan=args.nan,
            date_format=args.date_format,
            filename_prefix=args.prefix,
            filename_suffix=args.suffix,
            hierarchical=args.hierarchical or args.orient == "hierarchical",
        )

        # æ ¹æ®ç»“æœè®¾ç½®é€€å‡ºç 
        if stats["failed_conversions"] > 0:
            sys.exit(1)
        else:
            sys.exit(0)

    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # å¦‚æœä½œä¸ºè„šæœ¬è¿è¡Œï¼Œæ‰§è¡Œå‘½ä»¤è¡Œç‰ˆæœ¬
    if len(sys.argv) > 1:
        main()
    else:
        # äº¤äº’å¼ä½¿ç”¨ç¤ºä¾‹
        print("Excelè½¬JSONå·¥å…· - äº¤äº’å¼æ¨¡å¼")
        print("=" * 40)

        # ç¤ºä¾‹ç”¨æ³•
        excel_file = input("è¯·è¾“å…¥Excelæ–‡ä»¶è·¯å¾„: ").strip()
        if not excel_file:
            print("æœªæä¾›æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨ç¤ºä¾‹...")
            excel_file = "sample.xlsx"  # æ›¿æ¢ä¸ºä½ çš„Excelæ–‡ä»¶

        try:
            converter = ExcelToJsonConverter(excel_file)

            print("\né€‰æ‹©è½¬æ¢é€‰é¡¹:")
            print("1. é»˜è®¤è®¾ç½® (recordsæ ¼å¼ï¼Œä¿ç•™nullå€¼)")
            print("2. å±‚çº§ç»“æ„æ ¼å¼ (é€‚åˆä½ çš„æ¡¥æ¢éƒ¨ä»¶è¡¨æ ¼)")
            print("3. è‡ªå®šä¹‰è®¾ç½®")

            choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()

            if choice == "2":
                print("ğŸ—ï¸  ä½¿ç”¨å±‚çº§ç»“æ„æ ¼å¼è½¬æ¢...")
                converter.convert_all_sheets(orient="hierarchical", hierarchical=True)
            elif choice == "3":
                orient = (
                    input(
                        "JSONæ ¼å¼ (records/index/values/table/hierarchical) [records]: "
                    ).strip()
                    or "records"
                )
                hierarchical = input("ä½¿ç”¨å±‚çº§ç»“æ„ï¼Ÿ(y/n) [n]: ").strip().lower() == "y"
                handle_nan = (
                    input("NaNå¤„ç† (null/drop/fill) [null]: ").strip() or "null"
                )
                date_format = input("æ—¥æœŸæ ¼å¼ (iso/epoch) [iso]: ").strip() or "iso"
                prefix = input("æ–‡ä»¶åå‰ç¼€ [ç©º]: ").strip()
                suffix = input("æ–‡ä»¶ååç¼€ [ç©º]: ").strip()

                converter.convert_all_sheets(
                    orient, handle_nan, date_format, prefix, suffix, hierarchical
                )
            else:
                converter.convert_all_sheets()

        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
