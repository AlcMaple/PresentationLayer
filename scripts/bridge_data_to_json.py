import pandas as pd
import json
import os
from datetime import datetime


class BridgeDataJsonConverter:
    """æ¡¥æ¢æ•°æ®JSONè½¬æ¢å™¨"""

    def __init__(self, file_path):
        self.file_path = file_path
        self.hierarchy_columns = [
            "æ¡¥æ¢ç±»å‹",
            "éƒ¨ä½",
            "ç»“æ„ç±»å‹",
            "éƒ¨ä»¶ç±»å‹",
            "æ„ä»¶å½¢å¼",
            "ç—…å®³ç±»å‹",
            "æ ‡åº¦",
            "å®šæ€§æè¿°",
            "å®šé‡æè¿°",
        ]

    def get_available_sheets(self):
        """è·å–æ‰€æœ‰å¯ç”¨çš„å·¥ä½œè¡¨"""
        try:
            excel_data = pd.read_excel(self.file_path, sheet_name=None)
            return list(excel_data.keys())
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return []

    def extract_hierarchical_structure(self, sheet_name):
        """æå–å±‚çº§å…³ç³»ç»“æ„"""
        try:
            # è¯»å–å·¥ä½œè¡¨
            df = pd.read_excel(self.file_path, sheet_name=sheet_name, header=None)

            print(f"æ­£åœ¨å¤„ç†å·¥ä½œè¡¨: {sheet_name}")
            print(f"æ•°æ®å½¢çŠ¶: {df.shape}")

            if df is None or len(df) < 2:
                print("æ•°æ®è¡Œæ•°ä¸è¶³")
                return None

            # ä½¿ç”¨ç¬¬äºŒè¡Œä½œä¸ºåˆ—æ ‡é¢˜ï¼Œä»ç¬¬ä¸‰è¡Œå¼€å§‹æ˜¯æ•°æ®
            header_row = df.iloc[1].fillna("")
            data_df = df.iloc[2:].copy()
            data_df.columns = header_row

            # æ¸…ç†åˆ—å
            clean_columns = []
            for col in data_df.columns:
                if pd.isna(col) or col == "":
                    clean_columns.append(f"æœªå‘½å_{len(clean_columns)}")
                else:
                    clean_columns.append(str(col))

            data_df.columns = clean_columns

            # ç¡®ä¿æˆ‘ä»¬æœ‰è¶³å¤Ÿçš„åˆ—ï¼Œæ˜ å°„åˆ°æ ‡å‡†åˆ—å
            expected_columns = self.hierarchy_columns
            if len(data_df.columns) >= len(expected_columns):
                data_df.columns = expected_columns + list(
                    data_df.columns[len(expected_columns) :]
                )
            else:
                data_df.columns = expected_columns[: len(data_df.columns)]

            # é‡ç½®ç´¢å¼•
            data_df = data_df.reset_index(drop=True)

            # å¤„ç†åˆå¹¶å•å…ƒæ ¼ - å‘ä¸‹å¡«å……ç©ºå€¼
            hierarchy_cols = expected_columns[:6]  # åˆ°ç—…å®³ç±»å‹ä¸ºæ­¢
            for col in hierarchy_cols:
                if col in data_df.columns:
                    data_df[col] = data_df[col].replace("", pd.NA)
                    data_df[col] = data_df[col].where(data_df[col].notna(), pd.NA)
                    data_df[col] = data_df[col].fillna(method="ffill")

            print(f"å¤„ç†åçš„æ•°æ®è¡Œæ•°: {len(data_df)}")

            # æ„å»ºJSONç»“æ„
            json_structure = self.build_json_structure(data_df)

            return json_structure

        except Exception as e:
            print(f"æå–å±‚çº§ç»“æ„æ—¶å‡ºé”™: {e}")
            import traceback

            traceback.print_exc()
            return None

    def build_json_structure(self, data_df):
        """æ„å»ºJSONç»“æ„"""
        result = {
            "metadata": {
                "export_time": datetime.now().isoformat(),
                "total_records": len(data_df),
                "columns": list(data_df.columns),
            },
            "bridge_types": {},
        }

        # æŒ‰æ¡¥æ¢ç±»å‹åˆ†ç»„
        bridge_types = data_df["æ¡¥æ¢ç±»å‹"].dropna().unique()
        bridge_types = [
            bt for bt in bridge_types if str(bt).strip() and str(bt) != "nan"
        ]

        print(f"å‘ç°çš„æ¡¥æ¢ç±»å‹: {bridge_types}")

        for bridge_type in bridge_types:
            print(f"å¤„ç†æ¡¥æ¢ç±»å‹: {bridge_type}")
            bridge_data = data_df[data_df["æ¡¥æ¢ç±»å‹"] == bridge_type].copy()

            result["bridge_types"][bridge_type] = {
                "name": bridge_type,
                "record_count": len(bridge_data),
                "parts": {},
            }

            # æ„å»ºé€’å½’ç»“æ„
            self.build_recursive_json(
                bridge_data,
                result["bridge_types"][bridge_type]["parts"],
                ["éƒ¨ä½", "ç»“æ„ç±»å‹", "éƒ¨ä»¶ç±»å‹", "æ„ä»¶å½¢å¼", "ç—…å®³ç±»å‹"],
                ["æ ‡åº¦", "å®šæ€§æè¿°", "å®šé‡æè¿°"],
            )

        return result

    def build_recursive_json(self, data, current_dict, hierarchy_levels, detail_levels):
        """é€’å½’æ„å»ºJSONç»“æ„"""
        if not hierarchy_levels:
            # åˆ°è¾¾æœ€æ·±å±‚ï¼Œæ„å»ºè¯¦ç»†ä¿¡æ¯
            self.build_detail_json(data, current_dict, detail_levels)
            return

        current_level = hierarchy_levels[0]
        remaining_levels = hierarchy_levels[1:]

        # è·å–å½“å‰å±‚çº§çš„æ‰€æœ‰å”¯ä¸€å€¼
        unique_values = data[current_level].dropna().unique()
        unique_values = [
            val for val in unique_values if str(val).strip() and str(val) != "nan"
        ]

        for value in unique_values:
            filtered_data = data[data[current_level] == value]

            current_dict[value] = {
                "name": value,
                "level": current_level,
                "record_count": len(filtered_data),
                "children": {} if remaining_levels else {"details": {}},
            }

            if remaining_levels:
                self.build_recursive_json(
                    filtered_data,
                    current_dict[value]["children"],
                    remaining_levels,
                    detail_levels,
                )
            else:
                self.build_detail_json(
                    filtered_data,
                    current_dict[value]["children"]["details"],
                    detail_levels,
                )

    def build_detail_json(self, data, current_dict, detail_levels):
        """æ„å»ºè¯¦ç»†ä¿¡æ¯çš„JSONç»“æ„"""
        # å¤„ç†æ ‡åº¦
        scale_values = data["æ ‡åº¦"].dropna().unique()
        scale_values = [
            val for val in scale_values if str(val).strip() and str(val) != "nan"
        ]

        for scale in scale_values:
            scale_data = data[data["æ ‡åº¦"] == scale]
            current_dict[str(scale)] = {
                "scale": str(scale),
                "qualitative_descriptions": {},
            }

            # å¤„ç†å®šæ€§æè¿°
            qual_values = scale_data["å®šæ€§æè¿°"].dropna().unique()
            qual_values = [
                val for val in qual_values if str(val).strip() and str(val) != "nan"
            ]

            for qual_desc in qual_values:
                qual_data = scale_data[scale_data["å®šæ€§æè¿°"] == qual_desc]
                current_dict[str(scale)]["qualitative_descriptions"][str(qual_desc)] = {
                    "description": str(qual_desc),
                    "quantitative_descriptions": {},
                }

                # å¤„ç†å®šé‡æè¿°
                quan_values = qual_data["å®šé‡æè¿°"].dropna().unique()
                quan_values = [
                    val for val in quan_values if str(val).strip() and str(val) != "nan"
                ]

                for quan_desc in quan_values:
                    current_dict[str(scale)]["qualitative_descriptions"][
                        str(qual_desc)
                    ]["quantitative_descriptions"][str(quan_desc)] = {
                        "description": str(quan_desc),
                        "is_complete": True,
                    }

    def convert_all_sheets_to_json(self, output_dir="json_output"):
        """è½¬æ¢æ‰€æœ‰å·¥ä½œè¡¨ä¸ºJSONæ–‡ä»¶"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        sheet_names = self.get_available_sheets()
        if not sheet_names:
            print("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„å·¥ä½œè¡¨")
            return

        all_sheets_data = {
            "metadata": {
                "source_file": self.file_path,
                "export_time": datetime.now().isoformat(),
                "total_sheets": len(sheet_names),
                "sheet_names": sheet_names,
            },
            "sheets": {},
        }

        for sheet_name in sheet_names:
            print(f"\n{'='*50}")
            print(f"æ­£åœ¨è½¬æ¢å·¥ä½œè¡¨: {sheet_name}")
            print("=" * 50)

            try:
                # æå–è¯¥å·¥ä½œè¡¨çš„æ•°æ®
                sheet_data = self.extract_hierarchical_structure(sheet_name)

                if sheet_data:
                    # ä¿å­˜å•ä¸ªå·¥ä½œè¡¨çš„JSONæ–‡ä»¶
                    sheet_filename = (
                        f"{sheet_name.replace('/', '_').replace('â€”', '_')}.json"
                    )
                    sheet_filepath = os.path.join(output_dir, sheet_filename)

                    with open(sheet_filepath, "w", encoding="utf-8") as f:
                        json.dump(sheet_data, f, ensure_ascii=False, indent=2)

                    print(f"âœ“ å·²ä¿å­˜: {sheet_filepath}")

                    # æ·»åŠ åˆ°æ€»æ•°æ®ä¸­
                    all_sheets_data["sheets"][sheet_name] = sheet_data

                else:
                    print(f"âœ— å·¥ä½œè¡¨ {sheet_name} æ•°æ®æå–å¤±è´¥")

            except Exception as e:
                print(f"âœ— å¤„ç†å·¥ä½œè¡¨ {sheet_name} æ—¶å‡ºé”™: {e}")

        # ä¿å­˜åŒ…å«æ‰€æœ‰å·¥ä½œè¡¨çš„æ€»JSONæ–‡ä»¶
        all_sheets_filepath = os.path.join(output_dir, "all_bridge_data.json")
        with open(all_sheets_filepath, "w", encoding="utf-8") as f:
            json.dump(all_sheets_data, f, ensure_ascii=False, indent=2)

        print(f"\n{'='*50}")
        print(f"âœ“ æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: {all_sheets_filepath}")
        print(f"âœ“ å•ç‹¬çš„å·¥ä½œè¡¨æ–‡ä»¶ä¿å­˜åœ¨: {output_dir} ç›®å½•")
        print("=" * 50)

        return all_sheets_data


def main():
    """ä¸»å‡½æ•°"""
    excel_file = "utils/work.xls"

    if not os.path.exists(excel_file):
        print(f"é”™è¯¯: æ–‡ä»¶ {excel_file} ä¸å­˜åœ¨")
        print("è¯·ç¡®ä¿æ–‡ä»¶åœ¨å½“å‰ç›®å½•ä¸‹")
        return

    print("=" * 60)
    print("æ¡¥æ¢æ•°æ®JSONè½¬æ¢å·¥å…·")
    print("=" * 60)

    # åˆ›å»ºè½¬æ¢å™¨
    converter = BridgeDataJsonConverter(excel_file)

    try:
        # è½¬æ¢æ‰€æœ‰å·¥ä½œè¡¨
        all_data = converter.convert_all_sheets_to_json()

        if all_data:
            print(f"\nâœ… è½¬æ¢å®Œæˆ!")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: json_output/")
            print(f"ğŸ“„ ä¸»æ–‡ä»¶: json_output/all_bridge_data.json")
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            total_bridge_types = len(all_data.get("sheets", {}))
            print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"   â€¢ å¤„ç†çš„å·¥ä½œè¡¨æ•°é‡: {total_bridge_types}")

            for sheet_name, sheet_data in all_data.get("sheets", {}).items():
                bridge_types = len(sheet_data.get("bridge_types", {}))
                total_records = sheet_data.get("metadata", {}).get("total_records", 0)
                print(
                    f"   â€¢ {sheet_name}: {bridge_types}ç§æ¡¥æ¢ç±»å‹, {total_records}æ¡è®°å½•"
                )

        else:
            print("âŒ æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•æ•°æ®")

    except Exception as e:
        print(f"âŒ è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
